{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"8ngJyBTSv7of"},"outputs":[],"source":["# libraries\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Nw_RmxtoGUXx"},"outputs":[],"source":["# loss function\n","def plot_loss_both(history):\n","    plt.plot(history.history['loss'], label = 'E_in train')\n","    plt.plot(history.history['val_loss'], label='E_in test')\n","    plt.xlabel('Iterations')\n","    plt.ylabel('E_in')\n","    plt.legend()\n","    plt.grid(True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-7lNELEOwH1h"},"outputs":[],"source":["# deep neural network model\n","def build_and_compile_model(norm):\n","    model = keras.Sequential([\n","      norm,\n","      layers.Dense(64, activation='relu'),\n","      layers.Dense(64, activation='relu'),\n","      layers.Dense(1)\n","  ])\n","\n","    model.compile(loss='mean_absolute_error',\n","                optimizer=tf.keras.optimizers.Adam(0.001))\n","    return model"]},{"cell_type":"markdown","metadata":{"id":"D9vUovrm2M-n"},"source":["# Basic Model Training\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"No0pbOjHwCTP"},"outputs":[],"source":["if __name__ == '__main__':\n","  \n","  # Reading the train data\n","  data = pd.read_csv('Training_set_merged.csv', header = None)\n","  rows, columns = data.shape\n","  Y_val = data.iloc[:, columns - 2 : columns]\n","  X_val = data.iloc[:, 0 : columns - 2]\n","\n","  # Reading the test data\n","  data = pd.read_csv('Test_set_merged.csv', header = None)\n","  rows, columns = data.shape\n","  Y_test = data.iloc[:, columns - 2 : columns]\n","  X_test = data.iloc[:, 0 : columns - 2]\n","\n","  normalizer.adapt(np.array(X_train))\n","  dnn_model = build_and_compile_model(normalizer)\n","\n","  history = dnn_model.fit(\n","      X_train,\n","      Y_train,\n","      validation_data = (X_test, Y_test),\n","      verbose=0, epochs=100)\n","\n","  print(\"\\nThe Learning curve using the train data\")\n","  plot_loss_both(history)\n","\n","  test_results['dnn_model'] = dnn_model.evaluate(X_train, Y_train, verbose=0)\n","  print(\"\\nThe E_in for train data: \", \"{:.5f}\".format(test_results['dnn_model']), \"\\n\")\n","\n","  test_results['dnn_model'] = dnn_model.evaluate(X_test, Y_test, verbose=0)\n","  print(\"\\nThe E_in for test data: \", \"{:.5f}\".format(test_results['dnn_model']), \"\\n\")"]},{"cell_type":"markdown","metadata":{"id":"9-STYvgW22OM"},"source":["# Hyperparameter Tunining"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CAsUcb1e3DMa"},"outputs":[],"source":["model_tuned = keras.Sequential([normalizer,\n","      layers.Dense(200, activation='relu'),\n","      layers.Dense(200, activation='relu'),\n","      layers.Dense(200, activation='relu'),\n","      layers.Dense(200, activation='relu'),\n","      layers.Dense(1, activation='relu')\n","  ])\n","\n","model_tuned.compile(loss='mean_absolute_error',\n","                optimizer=tf.keras.optimizers.Adam(0.001))\n","\n","history_tuned = model_tuned.fit(X_val, Y_val, verbose=0, validation_split=0.2, epochs=100)\n","plot_loss(history_tuned, \"E_in tuned\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7W324e8l7QYI"},"outputs":[],"source":["from tensorflow.keras import regularizers\n","\n","model_tuned = keras.Sequential([normalizer,\n","      layers.Dense(200, activation='relu', kernel_regularizer=regularizers.l2(0.01)),\n","      layers.Dense(200, activation='relu', kernel_regularizer=regularizers.l2(0.01)),\n","      layers.Dense(200, activation='relu', kernel_regularizer=regularizers.l2(0.01)),\n","      layers.Dense(200, activation='relu', kernel_regularizer=regularizers.l2(0.01)),\n","      layers.Dense(1, activation='relu', kernel_regularizer=regularizers.l2(0.01))])\n","\n","model_tuned.compile(loss='mean_absolute_error',\n","                optimizer=tf.keras.optimizers.Adam(0.001))\n","\n","history_tuned = model_tuned.fit(X_val, Y_val, verbose=0, validation_split=0.2, epochs=100)\n","plot_loss(history_tuned, \"E_in tuned\")"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"_dDDYy3T7U2N"},"source":["# Generalization [$E_{out}$ using Hoefding's inequality]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SXjTYj3C7Tcs"},"outputs":[],"source":["from math import *\n","E_out = test_results['dnn_model'] + sqrt((0.0008 / len(Y_test)) * log((4 * ((2 * len(Y_test)) ** 18) + 1) / 0.001))\n","print (\"\\nThe E_out of the DNN model is:\", \"{:.5f}\".format(E_out))"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyPE9qWbrH8VtQcL1Es9ipbm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
